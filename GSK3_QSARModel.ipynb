{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fdiuu1_5-Uft"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn.model_selection\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, balanced_accuracy_score, fbeta_score\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the Dataset"
      ],
      "metadata": {
        "id": "lRq5IhFWbnXM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv('descriptorsGSK3.csv')"
      ],
      "metadata": {
        "id": "HjtGG1nwblhq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split the Dataset"
      ],
      "metadata": {
        "id": "uwfpe9vzb7R7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.drop('stripped_smiles', axis = 1)\n",
        "X = dataset.drop('gsk3', axis = 1)\n",
        "y = dataset['gsk3']\n",
        "# Split the dataset into random train and test subsets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state = 0, stratify = y)"
      ],
      "metadata": {
        "id": "GmCRRuRRBj-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imputation of missing values"
      ],
      "metadata": {
        "id": "_GasQcB6ZwxU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Complete NaN values in each column with the median\n",
        "X_train = X_train.fillna(X_train.median())\n",
        "X_test = X_test.fillna(dataset.median())"
      ],
      "metadata": {
        "id": "SJGBwD2UaDZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Standarization"
      ],
      "metadata": {
        "id": "XICpdkjO5nqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the scaler to the data and transform it\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "FR4wRTOGpOcd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest Model\n"
      ],
      "metadata": {
        "id": "rKSWB1PTekOU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_estimators = [10, 50, 70, 100, 150, 200]\n",
        "max_depth = [None, 5, 7, 10, 13, 15]\n",
        "# Create a dataframe to save the metrics for each set of parameters\n",
        "df_RF = pd.DataFrame(columns = ['n_estimators', 'max_depth', 'sensitivity', 'specificity', 'precision', 'f1_score', 'balanced_accuracy', 'fbeta_score'])\n",
        "for n in n_estimators:\n",
        "  for d in max_depth:\n",
        "    # Define the random forest classifier with its parameters\n",
        "    model = RandomForestClassifier(n_estimators = n, max_depth = d, n_jobs = 10, random_state = 0, class_weight = \"balanced\")\n",
        "    # Train the model with the train data\n",
        "    model.fit(X_train, y_train)\n",
        "    # The model make predictions for the test data\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Calculate the performance metrics\n",
        "    sensitivity = recall_score(y_test, y_pred)\n",
        "    specificity = recall_score(y_test, y_pred, pos_label = 0)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    f1_score = sklearn.metrics.f1_score(y_test, y_pred)\n",
        "    balanced_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
        "    fbeta_score = sklearn.metrics.fbeta_score(y_test, y_pred, beta = 2)\n",
        "    # Add metrics results\n",
        "    df_RF.loc[len(df_RF.index)] = [f\"{n}\", f\"{d}\", f\"{sensitivity}\", f\"{specificity}\", f\"{precision}\", f\"{f1_score}\", f\"{balanced_accuracy}\", f\"{fbeta_score}\"]"
      ],
      "metadata": {
        "id": "tb3gl3UAdxzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort the performance metrics by fbeta_score in ascending order\n",
        "df_RF = df_RF.sort_values(by = \"fbeta_score\", ascending = False)\n",
        "df_RF.to_csv(\"GSK3_RFresults3csv\", index = False)"
      ],
      "metadata": {
        "id": "tZKLF7Lheyw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save models trained with train data"
      ],
      "metadata": {
        "id": "x3D0P3cvgUfz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = RandomForestClassifier(n_estimators = 100, max_depth = 10, n_jobs = 10, random_state = 0, class_weight = \"balanced\")\n",
        "model.fit(X_train, y_train)\n",
        "pickle.dump(model, open('modelRF_GSK3_100_10.pkl', 'wb'))"
      ],
      "metadata": {
        "id": "_nZ1GxZEgKaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RandomForestClassifier(n_estimators = 70, max_depth = 10, n_jobs = 10, random_state = 0, class_weight = \"balanced\")\n",
        "model.fit(X_train, y_train)\n",
        "pickle.dump(model, open('modelRF_GSK3_70_10.pkl', 'wb'))"
      ],
      "metadata": {
        "id": "6B9AL90ggQ1J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RandomForestClassifier(n_estimators = 150, max_depth = 10, n_jobs = 10, random_state = 0, class_weight = \"balanced\")\n",
        "model.fit(X_train, y_train)\n",
        "pickle.dump(model, open('modelRF_GSK3_150_10.pkl', 'wb'))"
      ],
      "metadata": {
        "id": "r1PjmXUwgTL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## C-Support Vector Classification Model\n"
      ],
      "metadata": {
        "id": "PlbJ4Y0JeTFK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "C_range = [3, 1, 0.01, 0.001]\n",
        "df_SVC = pd.DataFrame(columns = ['C', 'sensitivity', 'specificity', 'precision', 'f1_score', 'balanced_accuracy', 'fbeta_score'])\n",
        "for c in C_range:\n",
        "    model = SVC(C = c, probability = True, class_weight = \"balanced\",  random_state = 0)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    print(c)\n",
        "\n",
        "    # Calculate the performance metrics\n",
        "    sensitivity = recall_score(y_test, y_pred)\n",
        "    specificity = recall_score(y_test, y_pred, pos_label = 0)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    f1_score = sklearn.metrics.f1_score(y_test, y_pred)\n",
        "    balanced_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
        "    fbeta_score = sklearn.metrics.fbeta_score(y_test, y_pred, beta = 2)\n",
        "    df_SVC.loc[len(df_SVC.index)] = [f\"{c}\", f\"{sensitivity}\", f\"{specificity}\", f\"{precision}\", f\"{f1_score}\", f\"{balanced_accuracy}\", f\"{fbeta_score}\"]"
      ],
      "metadata": {
        "id": "JslghTYfedCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort the performance metrics by fbeta_score in ascending order\n",
        "df_SVC = df_SVC.sort_values(by = \"fbeta_score\", ascending = False)\n",
        "df_SVC.to_csv(\"GSK3_SVCresults.csv\", index = False)"
      ],
      "metadata": {
        "id": "Ixlc3qmUfPOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save models trained with train data"
      ],
      "metadata": {
        "id": "e3CZ9airIgEG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = SVC(C = 3, class_weight = \"balanced\",  random_state = 0)\n",
        "model.fit(X_train, y_train)\n",
        "pickle.dump(model, open('modelSVC_GSK3_3.pkl', 'wb'))"
      ],
      "metadata": {
        "id": "glKwwlo_Ig9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SVC(C = 1, class_weight = \"balanced\",  random_state = 0)\n",
        "model.fit(X_train, y_train)\n",
        "pickle.dump(model, open('modelSVC_GSK3_1.pkl', 'wb'))"
      ],
      "metadata": {
        "id": "cFYeYEpFIjv0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save Models trained with all data"
      ],
      "metadata": {
        "id": "mPmKDlGofyxQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Complete NaN in each column with the median\n",
        "X_without_NaN = X.fillna(X.median())\n",
        "# Fit the scaler to the data and transform it\n",
        "X_scl = scaler.fit_transform(X_without_NaN)"
      ],
      "metadata": {
        "id": "4Uu8BYjVgAVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save Random Forest Models"
      ],
      "metadata": {
        "id": "3V8BrqBsfcMG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = RandomForestClassifier(n_estimators = 100, max_depth = 10, n_jobs = 10, random_state = 0, class_weight = \"balanced\")\n",
        "model.fit(X_scl, y)\n",
        "pickle.dump(model, open('modelALLRF_GSK3_100_10.pkl', 'wb'))"
      ],
      "metadata": {
        "id": "gXWZ7OsSfnSB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RandomForestClassifier(n_estimators = 70, max_depth = 10, n_jobs = 10, random_state = 0, class_weight = \"balanced\")\n",
        "model.fit(X_scl, y)\n",
        "pickle.dump(model, open('modelALLRF_GSK3_70_10.pkl', 'wb'))"
      ],
      "metadata": {
        "id": "ZgSMtHIIfqdc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RandomForestClassifier(n_estimators = 150, max_depth = 10, n_jobs = 10, random_state = 0, class_weight = \"balanced\")\n",
        "model.fit(X_scl, y)\n",
        "pickle.dump(model, open('modelALLRF_GSK3_150_10.pkl', 'wb'))"
      ],
      "metadata": {
        "id": "zrVTJGVZfs-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save SVC Models"
      ],
      "metadata": {
        "id": "m30U_yy6gmBn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = SVC(C = 3, class_weight = \"balanced\",  random_state = 0)\n",
        "model.fit(X_scl, y)\n",
        "pickle.dump(model, open('modelALLSVC_GSK3_3.pkl', 'wb'))"
      ],
      "metadata": {
        "id": "rnzrVt7gf1Ot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SVC(C = 1, class_weight = \"balanced\",  random_state = 0)\n",
        "model.fit(X_scl, y)\n",
        "pickle.dump(model, open('modelALLSVC_GSK3_1.pkl', 'wb'))"
      ],
      "metadata": {
        "id": "Z9Eol9_3IqXS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}