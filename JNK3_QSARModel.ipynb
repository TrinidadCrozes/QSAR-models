{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNl7XvRMQQbr2eZl1ZdigyN"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QvQ_OWOS-aU4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn.model_selection\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, balanced_accuracy_score, fbeta_score\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the Dataset"
      ],
      "metadata": {
        "id": "9Tx0-_iT4KMk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv('descriptorsJNK3.csv')"
      ],
      "metadata": {
        "id": "PZG9fREx4OBU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split the Dataset"
      ],
      "metadata": {
        "id": "57d3EoAO4TIX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.drop('stripped_smiles', axis = 1)\n",
        "X = dataset.drop('jnk3', axis = 1)\n",
        "y = dataset['jnk3']\n",
        "# Split the dataset into random train and test subsets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state = 0, stratify = y)"
      ],
      "metadata": {
        "id": "2p69fxTz4W7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imputation of missing values"
      ],
      "metadata": {
        "id": "TDvq5_bE4goM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Complete NaN values in each column with the median\n",
        "X_train = X_train.fillna(X_train.median())\n",
        "X_test = X_test.fillna(dataset.median())"
      ],
      "metadata": {
        "id": "xQXeiMlv4Z9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Standarization"
      ],
      "metadata": {
        "id": "3U8dB86o4h3B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the scaler to the data and transform it\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "puK2NzxS4anG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest Model"
      ],
      "metadata": {
        "id": "LwiSSv9j4m2c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_estimators = [10, 50, 70, 100, 150, 200]\n",
        "max_depth = [None, 5, 7, 10, 13, 15]\n",
        "# Create a dataframe to save the metrics for each set of parameters\n",
        "df_RF = pd.DataFrame(columns = ['n_estimators', 'max_depth', 'sensitivity', 'specificity', 'precision', 'f1_score', 'balanced_accuracy', 'fbeta_score'])\n",
        "for n in n_estimators:\n",
        "  for d in max_depth:\n",
        "    # Define the random forest classifier with its parameters\n",
        "    model = RandomForestClassifier(n_estimators = n, max_depth = d, n_jobs = 4, random_state = 0, class_weight = \"balanced\")\n",
        "    # Train the model with the train data\n",
        "    model.fit(X_train, y_train)\n",
        "    # The model make predictions for the test data\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Calculate the performance metrics\n",
        "    sensitivity = recall_score(y_test, y_pred)\n",
        "    specificity = recall_score(y_test, y_pred, pos_label = 0)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    f1_score = sklearn.metrics.f1_score(y_test, y_pred)\n",
        "    balanced_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
        "    fbeta_score = sklearn.metrics.fbeta_score(y_test, y_pred, beta = 2)\n",
        "    # Add metrics results\n",
        "    df_RF.loc[len(df_RF.index)] = [f\"{n}\", f\"{d}\", f\"{sensitivity}\", f\"{specificity}\", f\"{precision}\", f\"{f1_score}\", f\"{balanced_accuracy}\", f\"{fbeta_score}\"]"
      ],
      "metadata": {
        "id": "dDJh1pa44pYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort the performance metrics by fbeta_score in ascending order\n",
        "df_RF = df_RF.sort_values(by = \"fbeta_score\", ascending = False)\n",
        "df_RF.to_csv(\"JNK3_RFresults.csv\", index = False)"
      ],
      "metadata": {
        "id": "qD_4aCFy4vQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save models trained with train data"
      ],
      "metadata": {
        "id": "K6O8UHQ6I6uU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = RandomForestClassifier(n_estimators = 200, max_depth = 7, n_jobs = 10, random_state = 0, class_weight = \"balanced\")\n",
        "model.fit(X_train, y_train)\n",
        "pickle.dump(model, open('modelRF_JNK3_200_7.pkl', 'wb'))"
      ],
      "metadata": {
        "id": "3PErkaSVI-qS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RandomForestClassifier(n_estimators = 150, max_depth = 7, n_jobs = 10, random_state = 0, class_weight = \"balanced\")\n",
        "model.fit(X_train, y_train)\n",
        "pickle.dump(model, open('modelRF_JNK3_150_7.pkl', 'wb'))"
      ],
      "metadata": {
        "id": "Z3r39xi4JCuu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RandomForestClassifier(n_estimators = 100, max_depth = 7, n_jobs = 10, random_state = 0, class_weight = \"balanced\")\n",
        "model.fit(X_train, y_train)\n",
        "pickle.dump(model, open('modelRF_JNK3_100_7.pkl', 'wb'))"
      ],
      "metadata": {
        "id": "8q75Jvm4JEPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## C-Support Vector Classification Model\n"
      ],
      "metadata": {
        "id": "CaACfzyw4sa0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "C_range = [1, 0.01, 0.001]\n",
        "df_SVC = pd.DataFrame(columns = ['C', 'sensitivity', 'specificity', 'precision', 'f1_score', 'balanced_accuracy', 'fbeta_score'])\n",
        "for c in C_range:\n",
        "    model = SVC(C = c, probability = True, class_weight = \"balanced\",  random_state = 0)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    print(c)\n",
        "\n",
        "    # Calculate the performance metrics\n",
        "    sensitivity = recall_score(y_test, y_pred)\n",
        "    specificity = recall_score(y_test, y_pred, pos_label = 0)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    f1_score = sklearn.metrics.f1_score(y_test, y_pred)\n",
        "    balanced_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
        "    fbeta_score = sklearn.metrics.fbeta_score(y_test, y_pred, beta = 2)\n",
        "    df_SVC.loc[len(df_SVC.index)] = [f\"{c}\", f\"{sensitivity}\", f\"{specificity}\", f\"{precision}\", f\"{f1_score}\", f\"{balanced_accuracy}\", f\"{fbeta_score}\"]"
      ],
      "metadata": {
        "id": "0_p3ri8i45hZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort the performance metrics by fbeta_score in ascending order\n",
        "df_SVC = df_SVC.sort_values(by = \"fbeta_score\", ascending = False)\n",
        "df_SVC.to_csv(\"JNK3_SVCresults.csv\", index = False)"
      ],
      "metadata": {
        "id": "zuIgh46146RF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save models trained with train data"
      ],
      "metadata": {
        "id": "9Q2AKb5EJImM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = SVC(C = 1, class_weight = \"balanced\",  random_state = 0)\n",
        "model.fit(X_train, y_train)\n",
        "pickle.dump(model, open('modelSVC_JNK3_1.pkl', 'wb'))"
      ],
      "metadata": {
        "id": "n2fLEWBNJI4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save Models trained with all data"
      ],
      "metadata": {
        "id": "T_MrIRX5JNuK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Complete NaN in each column with the median\n",
        "X_without_NaN = X.fillna(X.median())\n",
        "# Fit the scaler to the data and transform it\n",
        "X_scl = scaler.fit_transform(X_without_NaN)"
      ],
      "metadata": {
        "id": "bVytcizYJQb-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save Random Forest Models"
      ],
      "metadata": {
        "id": "JI_H5sOHJTLo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = RandomForestClassifier(n_estimators = 200, max_depth = 7, n_jobs = 10, random_state = 0, class_weight = \"balanced\")\n",
        "model.fit(X_scl, y)\n",
        "pickle.dump(model, open('modelALLRF_JNK3_200_7.pkl', 'wb'))"
      ],
      "metadata": {
        "id": "Molk_9V0JWn_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RandomForestClassifier(n_estimators = 150, max_depth = 7, n_jobs = 10, random_state = 0, class_weight = \"balanced\")\n",
        "model.fit(X_scl, y)\n",
        "pickle.dump(model, open('modelALLRF_JNK3_150_7.pkl', 'wb'))"
      ],
      "metadata": {
        "id": "Wy25puXxJYhr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RandomForestClassifier(n_estimators = 100, max_depth = 7, n_jobs = 10, random_state = 0, class_weight = \"balanced\")\n",
        "model.fit(X_scl, y)\n",
        "pickle.dump(model, open('modelALLRF_JNK3_100_7.pkl', 'wb'))"
      ],
      "metadata": {
        "id": "OYTV8-b2Jbfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save SVC Models"
      ],
      "metadata": {
        "id": "ogP2OQ9oJcIw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = SVC(C = 1, class_weight = \"balanced\",  random_state = 0)\n",
        "model.fit(X_scl, y)\n",
        "pickle.dump(model, open('modelALLSVC_JNK3_1.pkl', 'wb'))"
      ],
      "metadata": {
        "id": "rfYAeDpTJdv0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}